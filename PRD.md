# PRD: 映画メタ情報品質評価・改善ループシステムの機能拡張

## 概要

現在の映画メタ情報の品質評価・改善ループシステムは、CSVファイルから1件のみを処理する限定的な実装になっています。本PRDでは、以下の2つの主要な改善を実施します：

1. **CSVファイルの柔軟な切り替え**: 環境変数でCSVファイル名を指定できるようにし、異なるデータセットで簡単にテストできるようにする
2. **全レコード処理**: CSVファイルに含まれるすべての映画レコードを処理し、結果を1つのJSONファイルにまとめて保存する

これにより、開発者はデータセットを簡単に切り替えながら、大量の映画メタデータを効率的に評価・改善できるようになります。

## 目標

- 環境変数`CSV_FILENAME`でCSVファイル名を指定可能にする（`data/`ディレクトリは固定）
- CSVファイルに含まれる全レコードを順次処理する機能を実装する
- 処理中のエラーをログに記録し、処理終了時にエラーサマリーを出力する
- 出力ファイル名にタイムスタンプを含めて一意性を確保する
- 全体の進捗状況（例：「処理中: 3/10件完了」）をログ出力する
- すべての処理結果を1つのJSONファイルにまとめて保存する

## ユーザーストーリー

### US-001: CSV_FILENAMEの環境変数サポートを追加

**説明:** 開発者として、異なるCSVファイルを簡単に切り替えてテストできるよう、環境変数でCSVファイル名を指定したい。

**受け入れ基準:**

- [x] `config.py`の`csv_path`フィールドに環境変数`CSV_FILENAME`のサポートを追加する
- [x] `CSV_FILENAME`が設定されている場合は`data/{CSV_FILENAME}`を使用し、未設定の場合は既存のデフォルト値`data/movies_test3.csv`を使用する
- [x] `.env.example`に`CSV_FILENAME`の説明とサンプル値を追加する（例：`CSV_FILENAME=movies.csv`）
- [x] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [x] 既存のテストがすべて合格すること
- [x] テストカバレッジが基準値を満たすこと

### US-002: 複数レコード結果を保存するデータモデルの拡張

**説明:** 開発者として、複数の映画レコードの処理結果を1つのデータ構造で管理できるよう、新しいモデルを定義したい。

**受け入れ基準:**

- [x] `movie_metadata/models.py`に`BatchRefinementResult`モデルを追加する
- [x] `BatchRefinementResult`は以下のフィールドを含む：
  - `results: list[MetadataRefinementResult]` - 各映画の処理結果
  - `total_count: int` - 処理対象の総件数
  - `success_count: int` - 成功した件数
  - `error_count: int` - エラーが発生した件数
  - `errors: list[dict]` - エラー情報（映画タイトル、エラーメッセージを含む）
  - `processing_time: float` - 全体の処理時間（秒）
- [x] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [x] モデルの単体テストを作成し合格すること
- [x] テストカバレッジが基準値を満たすこと

### US-003: タイムスタンプ付きファイル名でJSON出力する機能を実装

**説明:** 開発者として、複数回の実行結果を区別できるよう、出力ファイル名にタイムスタンプを含めたい。

**受け入れ基準:**

- [x] `movie_metadata/refinement_writer.py`の`RefinementResultWriter`クラスを拡張する
- [x] 新しいメソッド`write_batch(batch_result: BatchRefinementResult, output_dir: Path)`を追加する
- [x] 出力ファイル名のフォーマットは`batch_refinement_result_{YYYYMMDD}_{HHMMSS}.json`とする（例：`batch_refinement_result_20260207_143025.json`）
- [x] `BatchRefinementResult`を適切にシリアライズしてJSON形式で保存する
- [x] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [x] 単体テストを作成し合格すること
- [x] テストカバレッジが基準値を満たすこと
- [x] コンソール出力やファイル出力で変更が正しく反映されることを確認する

### US-004: 複数レコードのループ処理と進捗表示を実装

**説明:** ユーザーとして、CSVファイルに含まれるすべての映画を順次処理し、進捗状況を把握できるようにしたい。

**受け入れ基準:**

- [x] `main_refine.py`の40行目の単一レコード処理を、全レコードをループ処理するように変更する
- [x] `main_refine.py`の40行目の単一レコード処理を、全レコードをループ処理するように変更する
- [x] 各レコードの処理前に「処理中: X/Y件完了（タイトル: 映画名）」形式でログ出力する
- [x] 処理開始時に全体の開始時刻を記録し、終了時に総処理時間を計算する
- [x] 各レコードの処理結果を`MetadataRefinementResult`のリストに蓄積する
- [x] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [x] テストがすべて合格すること
- [x] テストカバレッジが基準値を満たすこと
- [x] コンソール出力で進捗が正しく表示されることを確認する

### US-005: エラーハンドリングとエラーサマリーの実装

**説明:** 開発者として、一部のレコードでエラーが発生しても処理を継続し、エラー情報を記録して最後にサマリーを出力したい。

**受け入れ基準:**

- [x] `main_refine.py`のループ処理に`try-except`ブロックを追加し、個別のレコードのエラーをキャッチする
- [x] エラーが発生した場合は、映画タイトルとエラーメッセージをエラーリストに記録する
- [x] エラーが発生したレコードをスキップして、次のレコードの処理を続行する
- [x] 全レコード処理後に`BatchRefinementResult`を生成し、成功・失敗の統計情報を含める
- [x] 処理終了時にエラーサマリーをログ出力する（エラー件数、エラーが発生した映画のリスト）
- [x] `RefinementResultWriter.write_batch()`を使用して結果を保存する
- [x] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [x] テストがすべて合格すること
- [x] テストカバレッジが基準値を満たすこと
- [x] コンソール出力やファイル出力で変更が正しく反映されることを確認する

### US-006: 統合テストと動作確認

**説明:** 開発者として、すべての機能が正しく統合され、実際のCSVファイルで期待通りに動作することを確認したい。

**受け入れ基準:**

- [x] 環境変数`CSV_FILENAME`を設定して`main_refine.py`を実行し、指定したCSVファイルが読み込まれることを確認する
- [x] 複数レコードを含むCSVファイル（`movies.csv`など）を使用して全レコードが処理されることを確認する
- [x] 出力ディレクトリにタイムスタンプ付きのJSONファイルが生成されることを確認する
- [x] 生成されたJSONファイルにすべてのレコードの処理結果が含まれていることを確認する
- [x] 進捗ログが正しく出力されることを確認する（例：「処理中: 1/5件完了」）
- [x] 意図的にエラーを発生させて（存在しない映画など）、エラーハンドリングが正しく動作することを確認する
- [x] エラーサマリーが正しく出力されることを確認する
- [ ] 品質チェック（フォーマット、Lint、型チェック）が通過すること
- [ ] すべてのテストが合格すること
- [ ] テストカバレッジが基準値を満たすこと
- [ ] コンソール出力やファイル出力で変更が正しく反映されることを確認する

## 対象外事項

- 並列処理やマルチスレッド処理は実装しない（順次処理のみ）
- コマンドライン引数によるCSVパスの指定は実装しない（環境変数のみ）
- 処理の中断・再開機能は実装しない
- 個別のレコードごとにJSONファイルを分割して保存する機能は実装しない
- GUIやWebインターフェースは実装しない
- リトライロジック（エラー発生時の自動再試行）は実装しない

## 技術的考慮事項

### 既存コンポーネントの再利用

- `CSVReader`は既に全レコードを読み込む機能を持っているため、そのまま利用可能
- `MetadataRefiner`は1レコードずつ処理する設計のため、変更不要
- `RefinementResultWriter`に新しいメソッドを追加することで拡張可能

### データフロー

```
1. config.py: CSV_FILENAMEを環境変数から読み込み
   ↓
2. main_refine.py: CSVReaderで全レコードを読み込み
   ↓
3. main_refine.py: 各レコードをループ処理
   - MetadataRefiner.refine()を呼び出し
   - エラーハンドリング
   - 進捗ログ出力
   ↓
4. main_refine.py: BatchRefinementResultを生成
   ↓
5. RefinementResultWriter: タイムスタンプ付きファイル名でJSON保存
```

### エラーハンドリングの詳細

- `MetadataRefiner.refine()`で発生する例外をキャッチ
- エラー情報（映画タイトル、エラーメッセージ、スタックトレース）をログに記録
- エラーリストに追加して処理を継続
- 最終的に`BatchRefinementResult.errors`に格納

### ファイル命名ルール

- フォーマット: `batch_refinement_result_{YYYYMMDD}_{HHMMSS}.json`
- 例: `batch_refinement_result_20260207_143025.json`
- タイムスタンプは処理開始時刻を使用
- `datetime.now().strftime("%Y%m%d_%H%M%S")`で生成
